# ğŸ¯ DeepSeekå¯¹è¯æ–‡æ¡£åŒ–ç³»ç»Ÿ - æœ€å°å¯è¡Œæ¶æ„(MVP)

åŸºäºæˆ‘ä»¬çš„æ·±åº¦è®¨è®ºï¼Œæˆ‘ä¸ºæ‚¨è®¾è®¡ä¸€ä¸ª**æœ€å°å¯è¡Œæ¶æ„**ï¼Œä¿ç•™æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼Œç¡®ä¿å¿«é€Ÿå®ç°å’Œç«‹å³ä½¿ç”¨ã€‚

## ğŸ—ï¸ ä¸€ã€MVPæ¶æ„æ€»è§ˆ

### 1.1 æ ¸å¿ƒåŸåˆ™
```
1. æœ€å°åŠŸèƒ½é›†ï¼šè§£å†³æœ€ç—›çš„ç‚¹
2. æœ€å¤§è‡ªåŠ¨åŒ–ï¼šæœ€å°‘æ‰‹åŠ¨æ“ä½œ  
3. æœ€å¿«è·¯å¾„ï¼šä»å¯¹è¯åˆ°æ–‡æ¡£çš„æœ€çŸ­è·¯å¾„
```

### 1.2 ä¸‰å±‚æœ€å°æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æµè§ˆå™¨æå–å±‚   â”‚    â”‚  Pythonå¤„ç†å±‚   â”‚    â”‚   æ–‡æ¡£è¾“å‡ºå±‚    â”‚
â”‚  (JS/æ’ä»¶)      â”‚    â”‚  (æœ¬åœ°è¿è¡Œ)     â”‚    â”‚  (Markdown)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å†…å®¹æå–      â”‚â”€â”€â”€â–¶â”‚ â€¢ æ ‡è®°è§£æ      â”‚â”€â”€â”€â–¶â”‚ â€¢ ç»“æ„ä¼˜åŒ–      â”‚
â”‚ â€¢ æ ‡è®°ç”Ÿæˆ      â”‚    â”‚ â€¢ æ ‡é¢˜è°ƒæ•´      â”‚    â”‚ â€¢ ç©ºè¡Œå¸ƒå±€      â”‚
â”‚ â€¢ ä¸€é”®å¯¼å‡º      â”‚    â”‚ â€¢ æ–‡æ¡£ç»„è£…      â”‚    â”‚ â€¢ æœ€ç»ˆè¾“å‡º      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ äºŒã€æµè§ˆå™¨æå–å±‚ï¼ˆæœ€å°å®ç°ï¼‰

### 2.1 æ ¸å¿ƒæ–‡ä»¶ï¼š`deepseek-extractor.js`
```javascript
// ==UserScript==
// @name         DeepSeekå¯¹è¯æå–å™¨
// @namespace    deepseek
// @version      1.0
// @description  æå–DeepSeekå¯¹è¯å¹¶æ·»åŠ æ ‡è®°
// @author       You
// @match        https://www.deepseek.com/chat/*
// @grant        none
// ==/UserScript==

(function() {
    'use strict';

    // æ ¸å¿ƒé…ç½®
    const CONFIG = {
        // å¯¹è¯å…ƒç´ é€‰æ‹©å™¨ï¼ˆå¯èƒ½éœ€è¦æ ¹æ®å®é™…é¡µé¢è°ƒæ•´ï¼‰
        SELECTORS: {
            messageContainer: '.message-container', // ç¤ºä¾‹ï¼Œéœ€å®é™…è°ƒæ•´
            userMessage: '[data-role="user"]',
            aiMessage: '[data-role="assistant"]',
            contentArea: '.prose'
        },
        
        // æ ‡è®°æ ¼å¼
        MARKERS: {
            conversationStart: '<!-- å¯¹è¯å¼€å§‹ | æ—¶é—´:{timestamp} -->',
            conversationEnd: '<!-- å¯¹è¯ç»“æŸ -->',
            roundStart: '<!-- è½®æ¬¡å¼€å§‹ | åºå·:{index} -->',
            roundEnd: '<!-- è½®æ¬¡ç»“æŸ -->',
            userInput: '<!-- ç”¨æˆ·è¾“å…¥ -->',
            aiOutputStart: '<!-- AIè¾“å‡ºå¼€å§‹ -->',
            aiOutputEnd: '<!-- AIè¾“å‡ºç»“æŸ -->'
        }
    };

    class DeepSeekExtractor {
        constructor() {
            this.conversationRounds = [];
            this.initUI();
        }

        // åˆå§‹åŒ–UI
        initUI() {
            const button = document.createElement('button');
            button.id = 'deepseek-extract-btn';
            button.innerHTML = 'ğŸ“¥ æå–å¯¹è¯';
            button.style.cssText = `
                position: fixed;
                top: 80px;
                right: 20px;
                z-index: 9999;
                background: #10a37f;
                color: white;
                border: none;
                border-radius: 20px;
                padding: 10px 20px;
                font-size: 14px;
                cursor: pointer;
                box-shadow: 0 2px 10px rgba(0,0,0,0.2);
            `;
            
            button.addEventListener('click', () => this.extractAndDownload());
            document.body.appendChild(button);
        }

        // æå–å¯¹è¯
        extractConversation() {
            this.conversationRounds = [];
            
            // æ–¹æ³•1ï¼šé€šè¿‡ç‰¹å®šé€‰æ‹©å™¨è·å–æ¶ˆæ¯
            const messages = document.querySelectorAll(CONFIG.SELECTORS.messageContainer);
            
            // æ–¹æ³•2ï¼šå¦‚æœé€‰æ‹©å™¨æ— æ•ˆï¼Œå°è¯•é€šè¿‡ç»“æ„è¯†åˆ«
            if (messages.length === 0) {
                this.extractByStructure();
                return;
            }
            
            // è¯†åˆ«ç”¨æˆ·å’ŒAIæ¶ˆæ¯
            let currentRound = null;
            
            messages.forEach((message, index) => {
                const isUser = message.querySelector(CONFIG.SELECTORS.userMessage);
                const isAI = message.querySelector(CONFIG.SELECTORS.aiMessage);
                
                if (isUser) {
                    // æ–°è½®æ¬¡å¼€å§‹
                    if (currentRound) {
                        this.conversationRounds.push(currentRound);
                    }
                    currentRound = {
                        user: this.extractContent(isUser),
                        ai: ''
                    };
                } else if (isAI && currentRound) {
                    currentRound.ai = this.extractContent(isAI);
                    this.conversationRounds.push(currentRound);
                    currentRound = null;
                }
            });
            
            // å¤„ç†æœ€åä¸€è½®
            if (currentRound && currentRound.user) {
                this.conversationRounds.push(currentRound);
            }
            
            console.log(`æå–åˆ° ${this.conversationRounds.length} è½®å¯¹è¯`);
        }

        // é€šè¿‡DOMç»“æ„è¯†åˆ«æ¶ˆæ¯ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
        extractByStructure() {
            // å¯»æ‰¾æ‰€æœ‰åŒ…å«æ–‡æœ¬çš„div
            const allDivs = document.querySelectorAll('div');
            const candidateDivs = [];
            
            allDivs.forEach(div => {
                if (div.textContent.trim().length > 50 && 
                    div.children.length > 0 &&
                    !div.querySelector('button')) {
                    candidateDivs.push(div);
                }
            });
            
            // ç®€å•çš„äº¤æ›¿è¯†åˆ«ï¼ˆå‡è®¾ç”¨æˆ·å’ŒAIäº¤æ›¿å‡ºç°ï¼‰
            for (let i = 0; i < candidateDivs.length; i += 2) {
                if (i + 1 < candidateDivs.length) {
                    this.conversationRounds.push({
                        user: this.simpleExtract(candidateDivs[i]),
                        ai: this.simpleExtract(candidateDivs[i + 1])
                    });
                }
            }
        }

        // æå–å†…å®¹
        extractContent(element) {
            // å°è¯•è·å–Markdownæ ¼å¼
            const markdownElement = element.querySelector(CONFIG.SELECTORS.contentArea);
            if (markdownElement) {
                return this.convertToMarkdown(markdownElement);
            }
            
            // å›é€€åˆ°ç®€å•æå–
            return this.simpleExtract(element);
        }

        // ç®€å•æå–ï¼ˆä¿æŒæ¢è¡Œï¼‰
        simpleExtract(element) {
            return element.innerText.replace(/\n\s*\n/g, '\n\n').trim();
        }

        // è½¬æ¢ä¸ºMarkdownï¼ˆç®€åŒ–ç‰ˆï¼‰
        convertToMarkdown(element) {
            // å…‹éš†ä»¥é¿å…ä¿®æ”¹åŸDOM
            const clone = element.cloneNode(true);
            
            // å¤„ç†ä»£ç å—
            const codeBlocks = clone.querySelectorAll('pre code, pre');
            codeBlocks.forEach(code => {
                const language = this.detectLanguage(code);
                const codeContent = code.textContent;
                code.parentNode.replaceChild(
                    document.createTextNode(`\`\`\`${language}\n${codeContent}\n\`\`\``), 
                    code
                );
            });
            
            // å¤„ç†æ ‡é¢˜ï¼ˆh1-h6ï¼‰
            const headings = clone.querySelectorAll('h1, h2, h3, h4, h5, h6');
            headings.forEach(heading => {
                const level = heading.tagName[1];
                const text = heading.textContent;
                heading.parentNode.replaceChild(
                    document.createTextNode(`${'#'.repeat(level)} ${text}`),
                    heading
                );
            });
            
            return clone.textContent.trim();
        }

        // æ£€æµ‹ä»£ç è¯­è¨€
        detectLanguage(codeElement) {
            const className = codeElement.className || '';
            const match = className.match(/language-(\w+)/);
            return match ? match[1] : '';
        }

        // ç”Ÿæˆæ ‡è®°æ–‡æœ¬
        generateMarkedText() {
            const lines = [];
            const timestamp = new Date().toISOString().split('T')[0];
            
            // å¯¹è¯å¼€å§‹æ ‡è®°
            lines.push(CONFIG.MARKERS.conversationStart.replace('{timestamp}', timestamp));
            lines.push('');
            
            // æ¯è½®å¯¹è¯
            this.conversationRounds.forEach((round, index) => {
                lines.push(CONFIG.MARKERS.roundStart.replace('{index}', index + 1));
                lines.push('');
                
                // ç”¨æˆ·è¾“å…¥
                lines.push(CONFIG.MARKERS.userInput);
                lines.push(round.user);
                lines.push('');
                
                // AIè¾“å‡º
                lines.push(CONFIG.MARKERS.aiOutputStart);
                lines.push(round.ai);
                lines.push(CONFIG.MARKERS.aiOutputEnd);
                lines.push('');
                
                lines.push(CONFIG.MARKERS.roundEnd);
                lines.push('');
                lines.push('---');
                lines.push('');
            });
            
            // å¯¹è¯ç»“æŸæ ‡è®°
            lines.push(CONFIG.MARKERS.conversationEnd);
            
            return lines.join('\n');
        }

        // ä¸‹è½½æ–‡ä»¶
        downloadFile(content, filename) {
            const blob = new Blob([content], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }

        // ä¸»æµç¨‹ï¼šæå–å¹¶ä¸‹è½½
        extractAndDownload() {
            try {
                // æå–å¯¹è¯
                this.extractConversation();
                
                if (this.conversationRounds.length === 0) {
                    alert('æœªæ£€æµ‹åˆ°å¯¹è¯å†…å®¹ï¼Œè¯·ç¡®ä¿é¡µé¢å·²åŠ è½½å®Œæˆ');
                    return;
                }
                
                // ç”Ÿæˆæ ‡è®°æ–‡æœ¬
                const markedText = this.generateMarkedText();
                
                // ç”Ÿæˆæ–‡ä»¶å
                const timestamp = new Date().toISOString()
                    .replace(/[:.]/g, '-')
                    .split('.')[0];
                const filename = `deepseek-conversation-${timestamp}.txt`;
                
                // ä¸‹è½½
                this.downloadFile(markedText, filename);
                
                // æç¤ºç”¨æˆ·
                alert(`æˆåŠŸæå– ${this.conversationRounds.length} è½®å¯¹è¯ï¼Œæ–‡ä»¶å·²ä¸‹è½½: ${filename}\n\nè¯·ä½¿ç”¨Pythonå¤„ç†å™¨è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚`);
                
            } catch (error) {
                console.error('æå–å¤±è´¥:', error);
                alert('æå–å¤±è´¥ï¼Œè¯·æ‰“å¼€å¼€å‘è€…å·¥å…·æŸ¥çœ‹é”™è¯¯ä¿¡æ¯');
            }
        }
    }

    // é¡µé¢åŠ è½½å®Œæˆååˆå§‹åŒ–
    window.addEventListener('load', () => {
        // å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
        setTimeout(() => {
            new DeepSeekExtractor();
        }, 2000);
    });

})();
```

### 2.2 å®‰è£…è¯´æ˜
```
1. å®‰è£…æµè§ˆå™¨ç”¨æˆ·è„šæœ¬ç®¡ç†å™¨ï¼š
   - Chrome: Tampermonkey
   - Firefox: Greasemonkey
   - Edge: Tampermonkey

2. æ–°å»ºç”¨æˆ·è„šæœ¬
3. ç²˜è´´ä¸Šé¢çš„ä»£ç 
4. ä¿å­˜å¹¶å¯ç”¨

5. è®¿é—®DeepSeekå¯¹è¯é¡µé¢
6. é¡µé¢å³ä¸Šè§’ä¼šå‡ºç°"ğŸ“¥ æå–å¯¹è¯"æŒ‰é’®
```

## ğŸ ä¸‰ã€Pythonå¤„ç†å±‚ï¼ˆæœ€å°å®ç°ï¼‰

### 3.1 é¡¹ç›®ç»“æ„
```
deepseek-processor/
â”œâ”€â”€ deepseek_processor.py    # ä¸»å¤„ç†ç¨‹åº
â”œâ”€â”€ requirements.txt         # ä¾èµ–æ–‡ä»¶
â”œâ”€â”€ config.yaml             # é…ç½®æ–‡ä»¶
â””â”€â”€ samples/                # ç¤ºä¾‹æ–‡ä»¶
    â””â”€â”€ conversation.txt    # ç¤ºä¾‹å¯¹è¯
```

### 3.2 ä¸»å¤„ç†æ–‡ä»¶ï¼š`deepseek_processor.py`
```python
#!/usr/bin/env python3
"""
DeepSeekå¯¹è¯æ–‡æ¡£ä¼˜åŒ–å¤„ç†å™¨ - MVPç‰ˆæœ¬
"""

import re
import argparse
import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Optional
import yaml

# ==================== æ•°æ®ç»“æ„ ====================

class ConversationRound:
    """å¯¹è¯è½®æ¬¡"""
    def __init__(self, index: int, user_input: str, ai_output: str):
        self.index = index
        self.user_input = user_input.strip()
        self.ai_output = ai_output.strip()
    
    def __repr__(self):
        return f"Round {self.index}: {self.user_input[:50]}..."

class Conversation:
    """å®Œæ•´å¯¹è¯"""
    def __init__(self, timestamp: str, rounds: List[ConversationRound]):
        self.timestamp = timestamp
        self.rounds = rounds
    
    @property
    def total_rounds(self):
        return len(self.rounds)

# ==================== æ ‡è®°è§£æå™¨ ====================

class MarkedFileParser:
    """è§£ææµè§ˆå™¨ç”Ÿæˆçš„æ ‡è®°æ–‡ä»¶"""
    
    def __init__(self):
        self.patterns = {
            'conversation_start': r'<!-- å¯¹è¯å¼€å§‹ \| æ—¶é—´:([^ ]+) -->',
            'conversation_end': r'<!-- å¯¹è¯ç»“æŸ -->',
            'round_start': r'<!-- è½®æ¬¡å¼€å§‹ \| åºå·:(\d+) -->',
            'round_end': r'<!-- è½®æ¬¡ç»“æŸ -->',
            'user_input': r'<!-- ç”¨æˆ·è¾“å…¥ -->',
            'ai_output_start': r'<!-- AIè¾“å‡ºå¼€å§‹ -->',
            'ai_output_end': r'<!-- AIè¾“å‡ºç»“æŸ -->'
        }
    
    def parse_file(self, file_path: str) -> Optional[Conversation]:
        """è§£ææ ‡è®°æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–å¯¹è¯æ—¶é—´
            time_match = re.search(self.patterns['conversation_start'], content)
            if not time_match:
                print(f"è­¦å‘Š: {file_path} ä¸­æœªæ‰¾åˆ°å¯¹è¯å¼€å§‹æ ‡è®°")
                return None
            
            timestamp = time_match.group(1)
            
            # æå–æ‰€æœ‰è½®æ¬¡
            rounds = self._extract_rounds(content)
            
            if not rounds:
                print(f"è­¦å‘Š: {file_path} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆè½®æ¬¡")
                return None
            
            return Conversation(timestamp, rounds)
            
        except Exception as e:
            print(f"è§£ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return None
    
    def _extract_rounds(self, content: str) -> List[ConversationRound]:
        """æå–æ‰€æœ‰å¯¹è¯è½®æ¬¡"""
        rounds = []
        
        # åˆ†å‰²è½®æ¬¡ï¼ˆåŸºäºè½®æ¬¡å¼€å§‹æ ‡è®°ï¼‰
        round_parts = re.split(self.patterns['round_start'], content)
        
        for i in range(1, len(round_parts), 2):
            if i >= len(round_parts):
                break
                
            round_index = int(round_parts[i])
            round_content = round_parts[i + 1]
            
            # æå–ç”¨æˆ·è¾“å…¥
            user_match = re.search(
                r'<!-- ç”¨æˆ·è¾“å…¥ -->\s*(.*?)\s*(?:<!-- AIè¾“å‡ºå¼€å§‹ -->|<!-- è½®æ¬¡ç»“æŸ -->)',
                round_content,
                re.DOTALL
            )
            
            # æå–AIè¾“å‡º
            ai_match = re.search(
                r'<!-- AIè¾“å‡ºå¼€å§‹ -->\s*(.*?)\s*<!-- AIè¾“å‡ºç»“æŸ -->',
                round_content,
                re.DOTALL
            )
            
            if user_match and ai_match:
                rounds.append(ConversationRound(
                    index=round_index,
                    user_input=user_match.group(1).strip(),
                    ai_output=ai_match.group(1).strip()
                ))
        
        return rounds

# ==================== æ ‡é¢˜ä¼˜åŒ–å™¨ ====================

class HeadingOptimizer:
    """æ ‡é¢˜å±‚çº§ä¼˜åŒ–å™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.heading_pattern = re.compile(r'^(#{1,6})\s+(.+)$', re.MULTILINE)
    
    def optimize_headings(self, content: str) -> str:
        """ä¼˜åŒ–æ ‡é¢˜å±‚çº§"""
        if not content:
            return content
        
        # æŸ¥æ‰¾æ‰€æœ‰æ ‡é¢˜
        headings = list(self.heading_pattern.finditer(content))
        
        if not headings:
            return content
        
        # åˆ†ææ ‡é¢˜å±‚çº§
        levels = [len(match.group(1)) for match in headings]
        min_level = min(levels)
        
        # è®¡ç®—è°ƒæ•´åç§»é‡
        adjustment = self._calculate_adjustment(min_level)
        
        if adjustment == 0:
            return content
        
        # åº”ç”¨è°ƒæ•´
        def replace_heading(match):
            level = len(match.group(1))
            text = match.group(2)
            new_level = min(6, max(1, level + adjustment))
            return f"{'#' * new_level} {text}"
        
        return self.heading_pattern.sub(replace_heading, content)
    
    def _calculate_adjustment(self, min_level: int) -> int:
        """è®¡ç®—æ ‡é¢˜è°ƒæ•´åç§»é‡"""
        strategy = self.config.get('heading_strategy', 'balanced')
        target_min = self.config.get('min_heading_level', 3)
        
        if strategy == 'conservative':
            # ä¿å®ˆï¼šåªåœ¨ç»å¯¹å¿…è¦æ—¶è°ƒæ•´
            if min_level == 1:
                return 2
            elif min_level == 2:
                return 1
            return 0
        
        elif strategy == 'aggressive':
            # æ¿€è¿›ï¼šç¡®ä¿æœ€å°å±‚çº§ä¸ºç›®æ ‡å€¼
            return target_min - min_level
        
        else:  # balanced (é»˜è®¤)
            # å¹³è¡¡ï¼šæ™ºèƒ½è°ƒæ•´
            if min_level == 1:
                return 2
            elif min_level == 2:
                return 1
            elif min_level >= 4:
                return -1  # å¦‚æœå±‚çº§è¿‡æ·±ï¼Œç¨å¾®æå‡
            return 0

# ==================== æ–‡æ¡£ç”Ÿæˆå™¨ ====================

class DocumentGenerator:
    """ç”Ÿæˆä¼˜åŒ–åçš„æ–‡æ¡£"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.heading_optimizer = HeadingOptimizer(config)
    
    def generate_document(self, conversation: Conversation, source_file: str) -> str:
        """ç”Ÿæˆå®Œæ•´æ–‡æ¡£"""
        lines = []
        
        # 1. æ–‡æ¡£æ ‡é¢˜
        doc_title = self._generate_document_title(conversation)
        lines.append(f"# {doc_title}")
        lines.append("")
        
        # 2. å…ƒæ•°æ®å—
        lines.extend(self._generate_metadata_block(conversation, source_file))
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # 3. å¯¹è¯è½®æ¬¡
        for round_data in conversation.rounds:
            lines.extend(self._generate_round_section(round_data))
            lines.append("")  # è½®æ¬¡é—´ç©ºè¡Œ
        
        # 4. æ–‡æ¡£ç»“æŸ
        lines.append("---")
        lines.append("")
        lines.append(f"*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
        
        return '\n'.join(lines)
    
    def _generate_document_title(self, conversation: Conversation) -> str:
        """ç”Ÿæˆæ–‡æ¡£æ ‡é¢˜"""
        if conversation.rounds:
            # ä»ç¬¬ä¸€è½®ç”¨æˆ·è¾“å…¥æå–æ ‡é¢˜
            first_input = conversation.rounds[0].user_input
            first_line = first_input.split('\n')[0].strip()
            
            # æ¸…ç†æ ‡é¢˜ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œé™åˆ¶é•¿åº¦ï¼‰
            title = re.sub(r'[#*`\[\]]', '', first_line)
            title = title[:60].strip()
            
            if len(first_line) > 60:
                title += "..."
            
            return title or "DeepSeekå¯¹è¯è®°å½•"
        return "æœªå‘½åå¯¹è¯"
    
    def _generate_metadata_block(self, conversation: Conversation, source_file: str) -> List[str]:
        """ç”Ÿæˆå…ƒæ•°æ®å—"""
        meta_lines = []
        
        # åŸºç¡€ä¿¡æ¯
        meta_lines.append(f"**å¯¹è¯æ—¶é—´**: {conversation.timestamp}")
        meta_lines.append(f"**å¯¹è¯è½®æ¬¡**: {conversation.total_rounds}")
        meta_lines.append(f"**æºæ–‡ä»¶**: {os.path.basename(source_file)}")
        meta_lines.append(f"**ç”Ÿæˆå·¥å…·**: DeepSeekå¯¹è¯å¤„ç†å™¨ v1.0")
        
        # æ ¼å¼åŒ–ä¸ºåˆ—è¡¨
        return [f"- {line}" for line in meta_lines]
    
    def _generate_round_section(self, round_data: ConversationRound) -> List[str]:
        """ç”Ÿæˆå•ä¸ªè½®æ¬¡éƒ¨åˆ†"""
        lines = []
        
        # è½®æ¬¡æ ‡é¢˜
        lines.append(f"## è½®æ¬¡ {round_data.index}")
        lines.append("")
        
        # ç”¨æˆ·è¾“å…¥
        lines.append("### ç”¨æˆ·è¾“å…¥")
        lines.append("")
        lines.append(self._format_user_input(round_data.user_input))
        lines.append("")
        
        # AIè¾“å‡ºï¼ˆåº”ç”¨æ ‡é¢˜ä¼˜åŒ–ï¼‰
        lines.append("### DeepSeekå›å¤")
        lines.append("")
        
        optimized_ai_output = self.heading_optimizer.optimize_headings(round_data.ai_output)
        lines.append(optimized_ai_output)
        lines.append("")
        
        # åˆ†éš”çº¿
        lines.append("---")
        
        return lines
    
    def _format_user_input(self, user_input: str) -> str:
        """æ ¼å¼åŒ–ç”¨æˆ·è¾“å…¥"""
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        lines = user_input.strip().split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.rstrip()
            if line or (formatted_lines and formatted_lines[-1]):
                formatted_lines.append(line)
        
        # ç¡®ä¿æœ€åä¸æ˜¯ç©ºè¡Œ
        while formatted_lines and not formatted_lines[-1]:
            formatted_lines.pop()
        
        return '\n'.join(formatted_lines)

# ==================== é…ç½®æ–‡ä»¶ç®¡ç† ====================

class ConfigManager:
    """é…ç½®æ–‡ä»¶ç®¡ç†"""
    
    DEFAULT_CONFIG = {
        'processing': {
            'heading_strategy': 'balanced',  # conservative|balanced|aggressive
            'min_heading_level': 3,
            'compress_excessive_depth': True,
        },
        'output': {
            'default_dir': './processed_docs',
            'auto_create_dir': True,
            'filename_template': '{title}_{date}.md',
        }
    }
    
    def __init__(self, config_path: str = None):
        self.config_path = config_path
        self.config = self.DEFAULT_CONFIG.copy()
        
        if config_path and os.path.exists(config_path):
            self.load_config(config_path)
    
    def load_config(self, config_path: str):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f) or {}
            
            # æ·±åº¦åˆå¹¶é…ç½®
            self._deep_merge(self.config, user_config)
            print(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
    
    def _deep_merge(self, base: Dict, update: Dict):
        """æ·±åº¦åˆå¹¶å­—å…¸"""
        for key, value in update.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._deep_merge(base[key], value)
            else:
                base[key] = value
    
    def get(self, key: str, default=None):
        """è·å–é…ç½®å€¼"""
        keys = key.split('.')
        value = self.config
        
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        
        return value

# ==================== å‘½ä»¤è¡Œç•Œé¢ ====================

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='DeepSeekå¯¹è¯æ–‡æ¡£ä¼˜åŒ–å¤„ç†å™¨ - MVPç‰ˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s conversation.txt              # å¤„ç†å•ä¸ªæ–‡ä»¶
  %(prog)s *.txt -o ./docs              # æ‰¹é‡å¤„ç†
  %(prog)s input.txt --no-optimize      # ä¸ä¼˜åŒ–æ ‡é¢˜å±‚çº§
  
è¾“å‡ºç¤ºä¾‹:
  ./docs/é¡¹ç›®æ¶æ„è®¾è®¡è®¨è®º_20240123.md
        """
    )
    
    parser.add_argument(
        'input_files',
        nargs='+',
        help='è¾“å…¥æ–‡ä»¶ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼Œå¦‚ *.txtï¼‰'
    )
    
    parser.add_argument(
        '-o', '--output-dir',
        default='./processed_docs',
        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./processed_docsï¼‰'
    )
    
    parser.add_argument(
        '-c', '--config',
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.yamlï¼‰'
    )
    
    parser.add_argument(
        '--no-optimize',
        action='store_true',
        help='ä¸ä¼˜åŒ–æ ‡é¢˜å±‚çº§ï¼ˆä¿æŒåŸæ ·ï¼‰'
    )
    
    parser.add_argument(
        '--strategy',
        choices=['conservative', 'balanced', 'aggressive'],
        default='balanced',
        help='æ ‡é¢˜ä¼˜åŒ–ç­–ç•¥ï¼ˆé»˜è®¤: balancedï¼‰'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–é…ç½®
    config_manager = ConfigManager(args.config)
    
    # æ›´æ–°å‘½ä»¤è¡Œå‚æ•°
    if args.no_optimize:
        config_manager.config['processing']['heading_strategy'] = 'none'
    else:
        config_manager.config['processing']['heading_strategy'] = args.strategy
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"DeepSeekå¯¹è¯å¤„ç†å™¨ v1.0")
    print(f"è¾“å‡ºç›®å½•: {output_dir.absolute()}")
    print("-" * 50)
    
    # å¤„ç†æ–‡ä»¶
    processed_count = 0
    failed_files = []
    
    for input_pattern in args.input_files:
        # å±•å¼€é€šé…ç¬¦
        input_files = list(Path().glob(input_pattern))
        
        for input_file in input_files:
            if not input_file.is_file():
                continue
            
            try:
                if args.verbose:
                    print(f"å¤„ç†: {input_file.name}")
                
                # è§£ææ–‡ä»¶
                parser = MarkedFileParser()
                conversation = parser.parse_file(str(input_file))
                
                if not conversation:
                    print(f"  âœ— æ— æ³•è§£æ: {input_file.name}")
                    failed_files.append((input_file.name, "è§£æå¤±è´¥"))
                    continue
                
                # ç”Ÿæˆæ–‡æ¡£
                generator = DocumentGenerator(config_manager.config)
                document = generator.generate_document(conversation, str(input_file))
                
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                output_filename = generate_output_filename(conversation, input_file)
                output_path = output_dir / output_filename
                
                # ä¿å­˜æ–‡ä»¶
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(document)
                
                processed_count += 1
                
                if args.verbose:
                    print(f"  âœ“ å·²ä¿å­˜: {output_filename} ({conversation.total_rounds}è½®)")
                
            except Exception as e:
                print(f"  âœ— å¤„ç†å¤±è´¥: {input_file.name} - {str(e)}")
                failed_files.append((input_file.name, str(e)))
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 50)
    print(f"å¤„ç†å®Œæˆ!")
    print("=" * 50)
    print(f"âœ“ æˆåŠŸå¤„ç†: {processed_count} ä¸ªæ–‡ä»¶")
    
    if failed_files:
        print(f"âœ— å¤„ç†å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶")
        for filename, error in failed_files:
            print(f"  - {filename}: {error}")
    
    print(f"\nè¾“å‡ºæ–‡ä»¶ä½äº: {output_dir.absolute()}")
    print("è¯·æŸ¥çœ‹è¯¥ç›®å½•ä¸‹çš„.mdæ–‡ä»¶è·å–å¤„ç†ç»“æœã€‚")

def generate_output_filename(conversation: Conversation, input_file: Path) -> str:
    """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å"""
    # ä»å¯¹è¯ç”Ÿæˆæ ‡é¢˜
    if conversation.rounds:
        title = conversation.rounds[0].user_input[:30]
        title = re.sub(r'[^\w\s-]', '', title)  # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        title = re.sub(r'[-\s]+', '_', title)   # æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
        title = title.strip('_')
    else:
        title = "conversation"
    
    # æ·»åŠ æ—¥æœŸ
    date_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # é™åˆ¶é•¿åº¦
    if len(title) > 40:
        title = title[:37] + "..."
    
    return f"{title}_{date_str}.md"

# ==================== é…ç½®æ–‡ä»¶ ====================

def create_default_config():
    """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
    config_content = """# DeepSeekå¯¹è¯å¤„ç†å™¨é…ç½®æ–‡ä»¶

# å¤„ç†é…ç½®
processing:
  # æ ‡é¢˜ä¼˜åŒ–ç­–ç•¥: conservative|balanced|aggressive
  heading_strategy: "balanced"
  
  # AIæ ‡é¢˜æœ€å°çº§åˆ« (1-6)
  min_heading_level: 3
  
  # å‹ç¼©è¿‡æ·±çš„æ ‡é¢˜å±‚çº§
  compress_excessive_depth: true

# è¾“å‡ºé…ç½®
output:
  # é»˜è®¤è¾“å‡ºç›®å½•
  default_dir: "./processed_docs"
  
  # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•
  auto_create_dir: true
  
  # æ–‡ä»¶åæ¨¡æ¿
  # å¯ç”¨å˜é‡: {title}, {date}, {time}, {rounds}
  filename_template: "{title}_{date}.md"

# ç©ºè¡Œå¸ƒå±€é…ç½®
spacing:
  # å¯¹è¯ä¹‹é—´ç©ºè¡Œæ•°
  between_conversations: 2
  
  # è½®æ¬¡ä¹‹é—´ç©ºè¡Œæ•°  
  between_rounds: 1
  
  # ç”¨æˆ·è¾“å…¥ä¸AIè¾“å‡ºä¹‹é—´ç©ºè¡Œæ•°
  between_qa: 1
"""
    
    with open('config.yaml', 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    print("å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: config.yaml")

# ==================== å…¥å£ç‚¹ ====================

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦é¦–æ¬¡è¿è¡Œï¼ˆæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼‰
    if not os.path.exists('config.yaml'):
        print("é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶...")
        create_default_config()
    
    # è¿è¡Œä¸»ç¨‹åº
    main()
```

### 3.3 ä¾èµ–æ–‡ä»¶ï¼š`requirements.txt`
```txt
# DeepSeekå¯¹è¯å¤„ç†å™¨ä¾èµ–
PyYAML>=6.0
```

### 3.4 å®‰è£…å’Œä½¿ç”¨è¯´æ˜

```
1. å®‰è£…Python 3.8+
2. å…‹éš†æˆ–åˆ›å»ºé¡¹ç›®ç›®å½•

3. å®‰è£…ä¾èµ–ï¼š
   pip install -r requirements.txt

4. é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶

5. ä½¿ç”¨æµè§ˆå™¨è„šæœ¬æå–å¯¹è¯ï¼Œä¿å­˜ä¸º.txtæ–‡ä»¶

6. è¿è¡Œå¤„ç†å™¨ï¼š
   python deepseek_processor.py conversation.txt

7. æ‰¹é‡å¤„ç†ï¼š
   python deepseek_processor.py *.txt -o ./docs -v

8. æŸ¥çœ‹ç”Ÿæˆçš„æ–‡æ¡£ï¼š
   ls ./docs/*.md
```

## ğŸ“‹ å››ã€æœ€å°åŠŸèƒ½æ¸…å•

### 4.1 æ ¸å¿ƒåŠŸèƒ½ï¼ˆå·²å®ç°ï¼‰
```
âœ… æµè§ˆå™¨ç«¯ï¼š
   - ä¸€é”®æå–DeepSeekå¯¹è¯
   - è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·/AIæ¶ˆæ¯
   - ä¿æŒä»£ç å—æ ¼å¼
   - æ·»åŠ ç»“æ„åŒ–æ ‡è®°
   - ä¸‹è½½ä¸º.txtæ–‡ä»¶

âœ… Pythonå¤„ç†ç«¯ï¼š
   - è§£ææ ‡è®°æ–‡ä»¶
   - æ™ºèƒ½æ ‡é¢˜å±‚çº§ä¼˜åŒ–
   - ç”Ÿæˆæ ‡å‡†Markdown
   - æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
   - æ‰¹é‡å¤„ç†æ”¯æŒ
   - é…ç½®æ–‡ä»¶ç®¡ç†

âœ… ç”¨æˆ·ä½“éªŒï¼š
   - ç®€å•å‘½ä»¤è¡Œç•Œé¢
   - æ¸…æ™°è¿›åº¦åé¦ˆ
   - é”™è¯¯å¤„ç†
   - è¾“å‡ºæ–‡æ¡£ç¾è§‚å¯ç”¨
```

### 4.2 å·¥ä½œæµç¨‹ï¼ˆæœ€å°ï¼‰
```
æ­¥éª¤1ï¼šåœ¨DeepSeekå®Œæˆå¯¹è¯
æ­¥éª¤2ï¼šç‚¹å‡»æµè§ˆå™¨æ’ä»¶"æå–å¯¹è¯"æŒ‰é’®
æ­¥éª¤3ï¼šè‡ªåŠ¨ä¸‹è½½æ ‡è®°æ–‡ä»¶ï¼ˆ.txtï¼‰
æ­¥éª¤4ï¼šè¿è¡ŒPythonå¤„ç†å™¨
æ­¥éª¤5ï¼šè·å¾—ä¼˜åŒ–åçš„Markdownæ–‡æ¡£
æ­¥éª¤6ï¼šç›´æ¥ä½¿ç”¨æ–‡æ¡£æˆ–æ”¾å…¥é¡¹ç›®
```

## ğŸš€ äº”ã€å¿«é€Ÿå¼€å§‹æŒ‡å—

### 5.1 30ç§’å®‰è£…æµ‹è¯•
```bash
# 1. å®‰è£…æµè§ˆå™¨è„šæœ¬ç®¡ç†å™¨ï¼ˆå¦‚Tampermonkeyï¼‰

# 2. åˆ›å»ºæ–°ç”¨æˆ·è„šæœ¬ï¼Œç²˜è´´JSä»£ç 

# 3. åˆ›å»ºPythoné¡¹ç›®ç›®å½•
mkdir deepseek-processor
cd deepseek-processor

# 4. åˆ›å»ºPythonæ–‡ä»¶
# ï¼ˆç²˜è´´ä¸Šé¢çš„Pythonä»£ç åˆ°deepseek_processor.pyï¼‰

# 5. å®‰è£…ä¾èµ–
pip install PyYAML

# 6. æµ‹è¯•è¿è¡Œ
python deepseek_processor.py --help
```

### 5.2 æµ‹è¯•å¯¹è¯æ–‡ä»¶ç¤ºä¾‹
```markdown
<!-- å¯¹è¯å¼€å§‹ | æ—¶é—´:2024-01-23 -->
<!-- è½®æ¬¡å¼€å§‹ | åºå·:1 -->
<!-- ç”¨æˆ·è¾“å…¥ -->
å¸®æˆ‘è®¾è®¡ä¸€ä¸ªREST APIçš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿ

<!-- AIè¾“å‡ºå¼€å§‹ -->
## ç”¨æˆ·è®¤è¯ç³»ç»Ÿè®¾è®¡

### JWTè®¤è¯æµç¨‹

```python
from datetime import datetime, timedelta
import jwt

def create_token(user_id: str) -> str:
    payload = {
        'user_id': user_id,
        'exp': datetime.utcnow() + timedelta(hours=24)
    }
    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')
```

#### å®‰å…¨è€ƒè™‘
1. ä½¿ç”¨HTTPS
2. ä»¤ç‰Œæœ‰æ•ˆæœŸ
3. åˆ·æ–°ä»¤ç‰Œæœºåˆ¶

<!-- AIè¾“å‡ºç»“æŸ -->
<!-- è½®æ¬¡ç»“æŸ -->
<!-- å¯¹è¯ç»“æŸ -->
```

### 5.3 é¢„æœŸè¾“å‡ºæ–‡æ¡£
```markdown
# å¸®æˆ‘è®¾è®¡ä¸€ä¸ªREST APIçš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿ

**å¯¹è¯æ—¶é—´**: 2024-01-23
**å¯¹è¯è½®æ¬¡**: 1
**æºæ–‡ä»¶**: deepseek-conversation-2024-01-23.txt
**ç”Ÿæˆå·¥å…·**: DeepSeekå¯¹è¯å¤„ç†å™¨ v1.0

---

## è½®æ¬¡ 1

### ç”¨æˆ·è¾“å…¥

å¸®æˆ‘è®¾è®¡ä¸€ä¸ªREST APIçš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿ

### DeepSeekå›å¤

#### ç”¨æˆ·è®¤è¯ç³»ç»Ÿè®¾è®¡

##### JWTè®¤è¯æµç¨‹

```python
from datetime import datetime, timedelta
import jwt

def create_token(user_id: str) -> str:
    payload = {
        'user_id': user_id,
        'exp': datetime.utcnow() + timedelta(hours=24)
    }
    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')
```

###### å®‰å…¨è€ƒè™‘
1. ä½¿ç”¨HTTPS
2. ä»¤ç‰Œæœ‰æ•ˆæœŸ
3. åˆ·æ–°ä»¤ç‰Œæœºåˆ¶

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: 2024-01-23 15:30:45*
```

## ğŸ“ˆ å…­ã€åç»­æ‰©å±•ç‚¹ï¼ˆå¯æš‚ä¸å®ç°ï¼‰

```
é˜¶æ®µ2æ‰©å±•ï¼ˆç¨³å®šåï¼‰ï¼š
1. æ›´æ™ºèƒ½çš„DOMè¯†åˆ«
2. è§†è§‰èŠ‚å¥å¼•æ“ï¼ˆæ™ºèƒ½ç©ºè¡Œï¼‰
3. å¯æŠ˜å å†…å®¹
4. å¯¼èˆªç³»ç»Ÿ
5. HTMLè¾“å‡ºæ ¼å¼

é˜¶æ®µ3æ‰©å±•ï¼ˆé«˜çº§ï¼‰ï¼š
1. å®æ—¶é¢„è§ˆ
2. é¡¹ç›®é›†æˆ
3. å›¢é˜Ÿåä½œ
4. äº‘åŒæ­¥
```

## ğŸ’¡ ä¸ƒã€æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
```
Q1: æµè§ˆå™¨è„šæœ¬æ— æ³•è¯†åˆ«å¯¹è¯
A1: è°ƒæ•´SELECTORSä¸­çš„é€‰æ‹©å™¨ï¼Œæˆ–ä½¿ç”¨å¼€å‘è€…å·¥å…·æ£€æŸ¥DOMç»“æ„

Q2: Pythonå¤„ç†å¤±è´¥
A2: æ£€æŸ¥æ ‡è®°æ–‡ä»¶æ ¼å¼ï¼Œç¡®ä¿ç¬¦åˆè§„èŒƒ

Q3: æ ‡é¢˜ä¼˜åŒ–ä¸ç¬¦åˆé¢„æœŸ
A3: ä¿®æ”¹config.yamlä¸­çš„heading_strategyé…ç½®

Q4: ç”Ÿæˆçš„æ–‡æ¡£ä¹±ç 
A4: ç¡®ä¿æ‰€æœ‰æ–‡ä»¶ä½¿ç”¨UTF-8ç¼–ç 
```

## ğŸ¯ å…«ã€æ€»ç»“

è¿™ä¸ªæœ€å°æ¶æ„å®ç°äº†ï¼š
1. **ä¸€é”®æå–**ï¼šæµè§ˆå™¨æ’ä»¶ç®€åŒ–æ“ä½œ
2. **æ™ºèƒ½ä¼˜åŒ–**ï¼šè‡ªåŠ¨è°ƒæ•´æ ‡é¢˜å±‚çº§
3. **æ ‡å‡†è¾“å‡º**ï¼šç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„Markdown
4. **é…ç½®çµæ´»**ï¼šæ”¯æŒä¸åŒä¼˜åŒ–ç­–ç•¥
5. **å¿«é€Ÿå®ç°**ï¼šæ€»å…±çº¦500è¡Œä»£ç 

**ç«‹å³è¡ŒåŠ¨å»ºè®®**ï¼š
1. å…ˆå®ç°æµè§ˆå™¨è„šæœ¬ï¼ˆ1å°æ—¶ï¼‰
2. æµ‹è¯•æå–åŠŸèƒ½ï¼ˆ30åˆ†é’Ÿï¼‰
3. å®ç°Pythonå¤„ç†å™¨ï¼ˆ2å°æ—¶ï¼‰
4. å®Œæ•´æµ‹è¯•å·¥ä½œæµï¼ˆ1å°æ—¶ï¼‰
5. å¼€å§‹ä½¿ç”¨å¹¶æ”¶é›†åé¦ˆ

è¿™ä¸ªæœ€å°æ¶æ„å®Œå…¨å¯ç”¨ï¼Œè§£å†³äº†æœ€æ ¸å¿ƒçš„ç—›ç‚¹ï¼š**ä»å¯¹è¯åˆ°ç»“æ„åŒ–æ–‡æ¡£çš„è‡ªåŠ¨è½¬æ¢**ã€‚åç»­å¯ä»¥æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µé€æ­¥å¢å¼ºåŠŸèƒ½ã€‚