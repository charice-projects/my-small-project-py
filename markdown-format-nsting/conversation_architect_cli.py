#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹è¯è®°å½•ç»“æ„åŒ–å¤„ç†å·¥å…· CLI ç‰ˆ
åŠŸèƒ½ï¼šæ™ºèƒ½å¤„ç†åµŒå¥—å¯¹è¯ï¼Œç”Ÿæˆæ¸…æ™°ç»“æ„åŒ–çš„æ–‡æ¡£
ä¼˜åŒ–ï¼šçº¯å‘½ä»¤è¡Œï¼Œæ”¯æŒè·¯å¾„è¾“å…¥ï¼Œæ™ºèƒ½å¤„ç†æ··åˆå†…å®¹
"""

import re
import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Optional, Any
import hashlib


class ConversationArchitectCLI:
    """å¯¹è¯è®°å½•å»ºç­‘å¸ˆ CLI ç‰ˆ - çº¯å‘½ä»¤è¡Œå¯¹è¯è®°å½•å¤„ç†"""
    
    def __init__(self, input_path: str, output_path: str = None, suffix: str = "_organized"):
        """
        åˆå§‹åŒ–å¯¹è¯å¤„ç†å™¨
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            suffix: è¾“å‡ºæ–‡ä»¶åç¼€ï¼ˆé»˜è®¤ï¼š_organizedï¼‰
        """
        self.input_path = Path(input_path).resolve()
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if output_path:
            self.output_path = Path(output_path).resolve()
        else:
            # ä½¿ç”¨é»˜è®¤åç¼€
            input_stem = self.input_path.stem
            input_parent = self.input_path.parent
            self.output_path = input_parent / f"{input_stem}{suffix}.md"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®æ–‡ä»¶
        self.config = {
            "max_nesting_level": 6,
            "preserve_code_blocks": True,
            "auto_adjust_headings": True,
            "extract_key_points": True,
            "generate_summary": True,
            "generate_toc": True,
            "toc_max_depth": 4,
            "fix_single_hash": True,
            "smart_merge": True,  # æ™ºèƒ½åˆå¹¶å·²ä¼˜åŒ–å’Œæœªä¼˜åŒ–å†…å®¹
            "auto_update_existing_toc": True,  # è‡ªåŠ¨æ›´æ–°å·²æœ‰ç›®å½•
            "add_main_title": True,  # æ·»åŠ æ€»æ ‡é¢˜
        }
        
        # å¤„ç†ç»Ÿè®¡
        self.stats = {
            "input_file": str(self.input_path),
            "output_file": str(self.output_path),
            "dialogs_count": 0,
            "turns_count": 0,
            "headings_fixed": 0,
            "sections_merged": 0,
            "toc_updated": False,
            "processing_time": None,
            "file_size": {
                "input": 0,
                "output": 0
            }
        }
        
        print(f"[ConversationArchitectCLI] åˆå§‹åŒ–å®Œæˆ")
        print(f"  è¾“å…¥æ–‡ä»¶: {self.input_path}")
        print(f"  è¾“å‡ºæ–‡ä»¶: {self.output_path}")
    
    def read_conversation_file(self) -> str:
        """è¯»å–å¯¹è¯æ–‡ä»¶"""
        try:
            with open(self.input_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            self.stats["file_size"]["input"] = len(content)
            print(f"[âˆš] æˆåŠŸè¯»å–æ–‡ä»¶ï¼Œå¤§å°: {len(content):,} å­—ç¬¦")
            return content
        except Exception as e:
            print(f"[Ã—] è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return ""
    
    def detect_content_structure(self, content: str) -> Dict[str, Any]:
        """
        æ™ºèƒ½æ£€æµ‹å†…å®¹ç»“æ„
        åŒºåˆ†ï¼šå·²ä¼˜åŒ–å†…å®¹ã€åŸå§‹å¯¹è¯ã€æ··åˆå†…å®¹
        """
        structure = {
            "has_existing_toc": False,
            "toc_start": -1,
            "toc_end": -1,
            "main_title": "",
            "is_already_organized": False,
            "sections": [],
            "dialogs": []
        }
        
        lines = content.split('\n')
        
        # æ£€æµ‹æ˜¯å¦å·²æœ‰ç›®å½•
        for i, line in enumerate(lines):
            if re.match(r'^#{1,2}\s*[ğŸ“‘ç›®å½•|Table of Contents]', line):
                structure["has_existing_toc"] = True
                structure["toc_start"] = i
                # æŸ¥æ‰¾ç›®å½•ç»“æŸä½ç½®
                for j in range(i + 1, len(lines)):
                    if lines[j].strip() == "" or re.match(r'^#{1,2}\s+', lines[j]):
                        structure["toc_end"] = j
                        break
                break
        
        # æ£€æµ‹æ˜¯å¦å·²æœ‰æ€»æ ‡é¢˜
        for i, line in enumerate(lines):
            if i < 5 and re.match(r'^#\s+[^#]', line):  # å‰5è¡Œä¸­çš„ä¸€çº§æ ‡é¢˜
                structure["main_title"] = line.strip()
                break
        
        # æ£€æµ‹æ˜¯å¦å·²ç»æ˜¯ä¼˜åŒ–åçš„æ ¼å¼
        organized_markers = [
            'å¯¹è¯å†å²æ¡£æ¡ˆé¦†',
            'å›åˆ \\d+:',
            'ğŸ“‹ æŒ‡ä»¤',
            'ğŸ¤– å“åº”'
        ]
        
        marker_count = 0
        for marker in organized_markers:
            if marker in content:
                marker_count += 1
        
        structure["is_already_organized"] = marker_count >= 2
        
        # æ£€æµ‹å¯¹è¯åˆ†æ®µ
        if structure["is_already_organized"]:
            print("[!] æ£€æµ‹åˆ°å·²ä¼˜åŒ–çš„å†…å®¹ï¼Œå°†è¿›è¡Œæ™ºèƒ½åˆå¹¶")
            return self._parse_organized_content(content, structure)
        else:
            print("[!] æ£€æµ‹åˆ°åŸå§‹å¯¹è¯å†…å®¹ï¼Œå°†è¿›è¡Œå®Œæ•´å¤„ç†")
            return self._parse_raw_content(content, structure)
    
    def _parse_organized_content(self, content: str, structure: Dict) -> Dict:
        """è§£æå·²ä¼˜åŒ–çš„å†…å®¹"""
        lines = content.split('\n')
        
        # æå–ç°æœ‰æ ‡é¢˜ç»“æ„
        current_section = None
        sections = []
        
        for i, line in enumerate(lines):
            # æ£€æµ‹ç« èŠ‚æ ‡é¢˜
            if line.startswith('## ') and 'å¯¹è¯-' in line:
                if current_section:
                    sections.append(current_section)
                
                # æå–å¯¹è¯ä¿¡æ¯
                dialog_match = re.match(r'^##\s+([^-\s]+)-?\s*(.+)$', line)
                if dialog_match:
                    dialog_id = dialog_match.group(1)
                    dialog_title = dialog_match.group(2)
                else:
                    dialog_id = f"dialog{len(sections)+1}"
                    dialog_title = line.replace('##', '').strip()
                
                current_section = {
                    "type": "dialog",
                    "dialog_id": dialog_id,
                    "title": dialog_title,
                    "start_line": i,
                    "end_line": -1,
                    "content": [line],
                    "turns": []
                }
            elif current_section:
                current_section["content"].append(line)
        
        # æ·»åŠ æœ€åä¸€ä¸ªç« èŠ‚
        if current_section:
            sections.append(current_section)
        
        structure["sections"] = sections
        
        # æå–å¯¹è¯å†…å®¹
        dialogs = self._extract_dialogs_from_sections(sections)
        structure["dialogs"] = dialogs
        
        return structure
    
    def _parse_raw_content(self, content: str, structure: Dict) -> Dict:
        """è§£æåŸå§‹å†…å®¹"""
        # æ£€æµ‹å¯¹è¯åˆ†æ®µ
        dialogs = self.detect_conversation_sections(content)
        structure["dialogs"] = dialogs
        return structure
    
    def detect_conversation_sections(self, content: str) -> List[Dict]:
        """
        æ£€æµ‹å¯¹è¯åˆ†æ®µ
        
        æ”¯æŒæ ¼å¼: 
        ## å¯¹è¯-V001 æ ‡é¢˜
        # å¯¹è¯-V001 æ ‡é¢˜
        ## å¯¹è¯-001 æ ‡é¢˜
        """
        # æ­£åˆ™åŒ¹é…å¯¹è¯æ ‡é¢˜
        dialog_pattern = r'^(?:#{1,2})\s+å¯¹è¯-([A-Za-z0-9]+)\s+(.+?)(?=^(?:#{1,2})\s+å¯¹è¯-|\Z)'
        
        # ç”±äºå¯¹è¯å¯èƒ½è·¨è¶Šå¤šè¡Œï¼Œæˆ‘ä»¬é€è¡Œå¤„ç†
        lines = content.split('\n')
        dialogs = []
        current_dialog = None
        dialog_content = []
        dialog_start_line = 0
        
        for i, line in enumerate(lines):
            # æ£€æµ‹å¯¹è¯å¼€å§‹
            match = re.match(r'^(#{1,2})\s+å¯¹è¯-([A-Za-z0-9]+)\s+(.+)$', line)
            if match:
                # ä¿å­˜å‰ä¸€ä¸ªå¯¹è¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if current_dialog is not None:
                    current_dialog["content"] = '\n'.join(dialog_content)
                    current_dialog["end_line"] = i - 1
                    dialogs.append(current_dialog)
                
                # å¼€å§‹æ–°å¯¹è¯
                level = len(match.group(1))
                dialog_id = match.group(2)
                dialog_title = match.group(3).strip()
                
                current_dialog = {
                    "id": dialog_id,
                    "raw_title": line,
                    "title": dialog_title,
                    "starting_level": level,
                    "content": "",
                    "start_line": i,
                    "end_line": -1,
                    "turns": [],
                    "metadata": {
                        "starting_line": i,
                        "raw_level": level,
                        "is_processed": False
                    }
                }
                
                dialog_content = [line]
                dialog_start_line = i
            elif current_dialog is not None:
                dialog_content.append(line)
        
        # æ·»åŠ æœ€åä¸€ä¸ªå¯¹è¯
        if current_dialog is not None:
            current_dialog["content"] = '\n'.join(dialog_content)
            current_dialog["end_line"] = len(lines) - 1
            dialogs.append(current_dialog)
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°å¯¹è¯æ ¼å¼ï¼Œå°è¯•å…¶ä»–æ ¼å¼
        if not dialogs:
            print("[!] æœªæ£€æµ‹åˆ°æ ‡å‡†å¯¹è¯æ ¼å¼ï¼Œå°è¯•å…¶ä»–æ£€æµ‹æ–¹æ³•...")
            dialogs = self._detect_alternative_sections(content)
        
        # å¤„ç†æ¯ä¸ªå¯¹è¯çš„å›åˆ
        total_turns = 0
        for dialog in dialogs:
            dialog_turns = self.extract_conversation_turns(dialog)
            dialog["turns"] = dialog_turns
            total_turns += len(dialog_turns)
        
        self.stats["dialogs_count"] = len(dialogs)
        self.stats["turns_count"] = total_turns
        
        print(f"[âˆš] æ£€æµ‹åˆ° {len(dialogs)} ä¸ªå¯¹è¯ï¼Œå…± {total_turns} ä¸ªå›åˆ")
        return dialogs
    
    def _detect_alternative_sections(self, content: str) -> List[Dict]:
        """æ£€æµ‹éæ ‡å‡†æ ¼å¼çš„å¯¹è¯åˆ†æ®µ"""
        lines = content.split('\n')
        sections = []
        current_section = None
        section_content = []
        
        for i, line in enumerate(lines):
            # æ£€æµ‹ä»»ä½•æ ‡é¢˜ï¼ˆ1-3çº§ï¼‰
            if re.match(r'^#{1,3}\s+', line):
                # ä¿å­˜å‰ä¸€ä¸ªç« èŠ‚
                if current_section is not None:
                    current_section["content"] = '\n'.join(section_content)
                    sections.append(current_section)
                
                # å¼€å§‹æ–°ç« èŠ‚
                level = len(re.match(r'^(#+)', line).group(1))
                title = line.replace('#', '').strip()
                
                # å°è¯•æå–ID
                id_match = re.search(r'([A-Za-z0-9]+)', title.split()[0] if title else '')
                dialog_id = id_match.group(1) if id_match else f"s{len(sections)+1:03d}"
                
                current_section = {
                    "id": dialog_id,
                    "raw_title": line,
                    "title": title,
                    "starting_level": level,
                    "content": "",
                    "start_line": i,
                    "end_line": -1,
                    "turns": [],
                    "metadata": {
                        "starting_line": i,
                        "raw_level": level,
                        "is_processed": False
                    }
                }
                
                section_content = [line]
            elif current_section is not None:
                section_content.append(line)
        
        # æ·»åŠ æœ€åä¸€ä¸ªç« èŠ‚
        if current_section is not None:
            current_section["content"] = '\n'.join(section_content)
            sections.append(current_section)
        
        return sections
    
    def _extract_dialogs_from_sections(self, sections: List[Dict]) -> List[Dict]:
        """ä»å·²æœ‰ç« èŠ‚ä¸­æå–å¯¹è¯"""
        dialogs = []
        
        for section in sections:
            if section["type"] == "dialog":
                # å·²ç»æ˜¯å¯¹è¯æ ¼å¼
                dialog = {
                    "id": section["dialog_id"],
                    "raw_title": f"## {section['dialog_id']} - {section['title']}",
                    "title": section["title"],
                    "content": '\n'.join(section["content"]),
                    "turns": self.extract_conversation_turns_from_content('\n'.join(section["content"])),
                    "metadata": {
                        "starting_line": section["start_line"],
                        "raw_level": 2,
                        "is_processed": True
                    }
                }
                dialogs.append(dialog)
        
        return dialogs
    
    def extract_conversation_turns(self, dialog: Dict) -> List[Dict]:
        """
        æå–å¯¹è¯ä¸­çš„æ¯ä¸ªå›åˆï¼ˆæŒ‡ä»¤-å“åº”å¯¹ï¼‰
        
        æ”¯æŒæ ¼å¼: 
        ### AAæˆ‘çš„æŒ‡ä»¤
        ### WWæˆ‘çš„æŒ‡ä»¤
        ## æˆ‘çš„æŒ‡ä»¤
        # æˆ‘çš„æŒ‡ä»¤
        """
        return self.extract_conversation_turns_from_content(dialog["content"])
    
    def extract_conversation_turns_from_content(self, content: str) -> List[Dict]:
        """ä»å†…å®¹ä¸­æå–å¯¹è¯å›åˆ"""
        lines = content.split('\n')
        turns = []
        
        # æ”¯æŒå¤šç§æŒ‡ä»¤æ ¼å¼
        instruction_patterns = [
            (r'^(#{1,3})\s+([A-Z]{2})æˆ‘çš„æŒ‡ä»¤\s*\n?', 'AAæˆ‘çš„æŒ‡ä»¤'),  # ### AAæˆ‘çš„æŒ‡ä»¤
            (r'^(#{1,3})\s+æˆ‘çš„æŒ‡ä»¤\s*\n?', 'æˆ‘çš„æŒ‡ä»¤'),  # ### æˆ‘çš„æŒ‡ä»¤
            (r'^(#{1,3})\s+æŒ‡ä»¤\s*\n?', 'æŒ‡ä»¤'),  # ### æŒ‡ä»¤
            (r'^(#{1,3})\s+Q\s*\n?', 'Q'),  # ### Q
        ]
        
        current_turn = None
        turn_lines = []
        in_turn = False
        
        for i, line in enumerate(lines):
            # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡ä»¤è¡Œ
            is_instruction = False
            instruction_type = "æœªçŸ¥æŒ‡ä»¤"
            
            for pattern, itype in instruction_patterns:
                match = re.match(pattern, line)
                if match:
                    is_instruction = True
                    instruction_type = itype
                    break
            
            if is_instruction:
                # ä¿å­˜å‰ä¸€ä¸ªå›åˆ
                if current_turn is not None and turn_lines:
                    turn_content = '\n'.join(turn_lines)
                    self._finalize_turn(current_turn, turn_content)
                    turns.append(current_turn)
                
                # å¼€å§‹æ–°å›åˆ
                current_turn = {
                    "turn_id": len(turns) + 1,
                    "instruction_type": instruction_type,
                    "raw_instruction_line": line,
                    "instruction": "",
                    "response": "",
                    "metadata": {
                        "line_number": i,
                        "is_processed": False
                    }
                }
                
                turn_lines = [line]
                in_turn = True
            elif in_turn:
                turn_lines.append(line)
        
        # æ·»åŠ æœ€åä¸€ä¸ªå›åˆ
        if current_turn is not None and turn_lines:
            turn_content = '\n'.join(turn_lines)
            self._finalize_turn(current_turn, turn_content)
            turns.append(current_turn)
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æŒ‡ä»¤ï¼Œå°†æ•´ä¸ªå†…å®¹ä½œä¸ºä¸€ä¸ªå›åˆ
        if not turns:
            turns.append({
                "turn_id": 1,
                "instruction_type": "å®Œæ•´å†…å®¹",
                "instruction": "å®Œæ•´å¯¹è¯",
                "response": content,
                "metadata": {
                    "line_number": 0,
                    "is_processed": False
                }
            })
        
        return turns
    
    def _finalize_turn(self, turn: Dict, content: str):
        """å®Œæˆå›åˆå†…å®¹æå–"""
        lines = content.split('\n')
        
        # ç¬¬ä¸€è¡Œæ˜¯æŒ‡ä»¤è¡Œ
        instruction_line = lines[0] if lines else ""
        
        # æå–æŒ‡ä»¤æ–‡æœ¬ï¼ˆæŒ‡ä»¤è¡Œä¹‹åçš„å†…å®¹ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜æˆ–ç»“æŸï¼‰
        instruction_text_lines = []
        response_lines = []
        
        in_instruction = True
        for line in lines[1:]:
            # æ£€æŸ¥æ˜¯å¦å¼€å§‹å“åº”éƒ¨åˆ†
            if in_instruction and (line.strip() == '' or re.match(r'^#{1,6}\s', line)):
                in_instruction = False
            
            if in_instruction:
                instruction_text_lines.append(line)
            else:
                response_lines.append(line)
        
        turn["instruction"] = '\n'.join(instruction_text_lines).strip()
        turn["response"] = '\n'.join(response_lines).strip()
        
        # æå–é™„åŠ ä¿¡æ¯
        turn["has_nesting"] = self._check_nesting(turn["response"])
        turn["code_blocks"] = self._extract_code_blocks(turn["response"])
        turn["tables"] = self._extract_tables(turn["response"])
        turn["diagrams"] = self._extract_diagrams(turn["response"])
        turn["action_items"] = self._extract_action_items(turn["response"])
    
    def _check_nesting(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦å­˜åœ¨æ ‡é¢˜åµŒå¥—é—®é¢˜"""
        heading_pattern = r'^(#{1,6})\s+(.+)$'
        headings = []
        
        for line in content.split('\n'):
            match = re.match(heading_pattern, line)
            if match:
                level = len(match.group(1))
                headings.append(level)
        
        # å¦‚æœæ ‡é¢˜å±‚çº§è¶…è¿‡4çº§æˆ–å­˜åœ¨è·³è·ƒï¼Œè®¤ä¸ºæœ‰åµŒå¥—é—®é¢˜
        if len(headings) > 1:
            max_level = max(headings) if headings else 0
            
            # æ£€æŸ¥å±‚çº§è·³è·ƒ
            for i in range(1, len(headings)):
                if headings[i] - headings[i-1] > 2:
                    return True
            
            # å¦‚æœæœ€å¤§å±‚çº§å¾ˆæ·±ï¼Œå¯èƒ½æœ‰é—®é¢˜
            if max_level > 5:
                return True
        
        return False
    
    def _extract_code_blocks(self, content: str) -> List[Dict]:
        """æå–ä»£ç å—"""
        code_blocks = []
        pattern = r'```([a-zA-Z0-9_+-]*)\n(.*?)```'
        
        for match in re.finditer(pattern, content, re.DOTALL):
            language = match.group(1) or 'text'
            code = match.group(2).strip()
            
            code_blocks.append({
                "language": language,
                "code": code,
                "length": len(code),
                "lines": code.count('\n') + 1
            })
        
        return code_blocks
    
    def _extract_tables(self, content: str) -> List[Dict]:
        """æå–è¡¨æ ¼"""
        tables = []
        lines = content.split('\n')
        
        in_table = False
        table_lines = []
        table_start = 0
        
        for i, line in enumerate(lines):
            if '|' in line and line.count('|') >= 2:
                if not in_table:
                    in_table = True
                    table_start = i
                table_lines.append(line)
            elif in_table:
                # è¡¨æ ¼ç»“æŸ
                if table_lines:
                    row_count = len([l for l in table_lines if '|' in l and '---' not in l])
                    col_count = table_lines[0].count('|') - 1 if table_lines else 0
                    
                    tables.append({
                        "start_line": table_start,
                        "lines": table_lines.copy(),
                        "row_count": row_count,
                        "col_count": col_count
                    })
                in_table = False
                table_lines = []
        
        # å¤„ç†æœ€åä¸€ä¸ªè¡¨æ ¼
        if in_table and table_lines:
            row_count = len([l for l in table_lines if '|' in l and '---' not in l])
            col_count = table_lines[0].count('|') - 1 if table_lines else 0
            
            tables.append({
                "start_line": table_start,
                "lines": table_lines.copy(),
                "row_count": row_count,
                "col_count": col_count
            })
        
        return tables
    
    def _extract_diagrams(self, content: str) -> List[Dict]:
        """æå–å›¾è¡¨å’Œæµç¨‹å›¾"""
        diagrams = []
        
        # Mermaid å›¾è¡¨
        mermaid_pattern = r'```mermaid\s*\n(.*?)```'
        for match in re.finditer(mermaid_pattern, content, re.DOTALL):
            diagrams.append({
                "type": "mermaid",
                "content": match.group(1).strip(),
                "lines": match.group(1).count('\n') + 1
            })
        
        return diagrams
    
    def _extract_action_items(self, content: str) -> List[Dict]:
        """æå–è¡ŒåŠ¨é¡¹"""
        action_items = []
        
        patterns = [
            (r'^\s*[-*â€¢]\s*(?:\[[ x]?\])?\s*(.+?)(?:\n|$)', 'bullet'),
            (r'^\d+\.\s*(.+?)(?:\n|$)', 'numbered'),
            (r'(?:ä¸‹ä¸€æ­¥|è¡ŒåŠ¨|ä»»åŠ¡|TODO|å¾…åŠ|è¡ŒåŠ¨é¡¹)[ï¼š:]\s*(.+?)(?:\n|$)', 'labeled'),
        ]
        
        lines = content.split('\n')
        for line_num, line in enumerate(lines):
            line_stripped = line.strip()
            
            for pattern, pattern_type in patterns:
                matches = re.findall(pattern, line_stripped, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        match_text = match[0]
                    else:
                        match_text = match
                    
                    match_text = match_text.strip()
                    if match_text and len(match_text) > 2:
                        action_items.append({
                            "text": match_text,
                            "line": line_num + 1,
                            "type": pattern_type,
                            "original": line_stripped
                        })
        
        return action_items
    
    def fix_all_headings(self, content: str, base_level: int = 2) -> Tuple[str, List[Dict]]:
        """
        ä¿®å¤æ‰€æœ‰æ ‡é¢˜å±‚çº§ï¼ŒåŒ…æ‹¬å•ä¸ª#å¼€å¤´çš„æ ‡é¢˜
        
        Args:
            content: åŸå§‹å†…å®¹
            base_level: åŸºç¡€å±‚çº§
            
        Returns:
            (ä¿®å¤åçš„å†…å®¹, æ ‡é¢˜ä¿¡æ¯åˆ—è¡¨)
        """
        lines = content.split('\n')
        fixed_lines = []
        headings_info = []
        
        current_context = 'normal'
        code_block_language = None
        
        i = 0
        while i < len(lines):
            line = lines[i]
            
            # æ£€æµ‹ä»£ç å—
            if line.strip().startswith('```'):
                fixed_lines.append(line)
                
                if current_context == 'code_block':
                    current_context = 'normal'
                    code_block_language = None
                else:
                    language_match = re.match(r'^```([a-zA-Z0-9_+-]*)', line)
                    code_block_language = language_match.group(1) if language_match else None
                    current_context = 'code_block'
                
                i += 1
                continue
            
            # åœ¨ä»£ç å—ä¸­ä¸å¤„ç†æ ‡é¢˜
            if current_context == 'code_block':
                fixed_lines.append(line)
                i += 1
                continue
            
            # æ£€æµ‹è¡¨æ ¼
            if '|' in line and ('---' in line or '--' in line or '===' in line):
                current_context = 'table'
                fixed_lines.append(line)
                i += 1
                continue
            elif current_context == 'table' and '|' not in line:
                current_context = 'normal'
            
            # å¤„ç†æ ‡é¢˜è¡Œ
            heading_match = re.match(r'^(#{1,6})\s+(.+)$', line)
            if heading_match:
                original_level = len(heading_match.group(1))
                title_text = heading_match.group(2).strip()
                
                # ä¿®å¤å•ä¸ª#å¼€å¤´çš„æ ‡é¢˜
                if original_level == 1 and self.config["fix_single_hash"]:
                    # å•ä¸ª#é€šå¸¸æ˜¯æ–‡æ¡£æ ‡é¢˜
                    new_level = 1
                else:
                    # è®¡ç®—æ–°çš„å±‚çº§
                    if "å¯¹è¯-" in title_text:
                        new_level = base_level
                    elif "æˆ‘çš„æŒ‡ä»¤" in title_text or "å›åˆ" in title_text:
                        new_level = base_level + 1
                    elif original_level <= 2:
                        new_level = base_level + 2
                    else:
                        new_level = min(original_level + 2, self.config["max_nesting_level"])
                
                # ç¡®ä¿å±‚çº§åˆç†
                new_level = max(1, min(new_level, self.config["max_nesting_level"]))
                
                # ç”Ÿæˆæ–°çš„æ ‡é¢˜è¡Œ
                new_heading = '#' * new_level + ' ' + title_text
                fixed_lines.append(new_heading)
                
                # è®°å½•æ ‡é¢˜ä¿¡æ¯
                if new_level <= self.config["toc_max_depth"]:
                    headings_info.append({
                        "level": new_level,
                        "text": title_text,
                        "original_level": original_level,
                        "line_num": i + 1
                    })
                
                # ç»Ÿè®¡ä¿®å¤çš„æ ‡é¢˜
                if original_level != new_level:
                    self.stats["headings_fixed"] += 1
            else:
                fixed_lines.append(line)
            
            i += 1
        
        fixed_content = '\n'.join(fixed_lines)
        return fixed_content, headings_info
    
    def generate_table_of_contents(self, headings: List[Dict], existing_toc: str = None) -> str:
        """
        ç”Ÿæˆç›®å½•ï¼Œå¯åŸºäºç°æœ‰ç›®å½•æ›´æ–°
        
        Args:
            headings: æ ‡é¢˜ä¿¡æ¯åˆ—è¡¨
            existing_toc: ç°æœ‰ç›®å½•å†…å®¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç›®å½•å­—ç¬¦ä¸²
        """
        if not headings or not self.config["generate_toc"]:
            return ""
        
        # å¦‚æœæœ‰ç°æœ‰ç›®å½•ä¸”å¯ç”¨äº†æ™ºèƒ½æ›´æ–°
        if existing_toc and self.config["auto_update_existing_toc"]:
            print("[!] æ£€æµ‹åˆ°ç°æœ‰ç›®å½•ï¼Œå°è¯•æ™ºèƒ½æ›´æ–°...")
            return self._update_existing_toc(existing_toc, headings)
        
        # ç”Ÿæˆæ–°ç›®å½•
        toc_lines = ["## ğŸ“‘ ç›®å½•", ""]
        
        for heading in headings:
            level = heading["level"]
            text = heading["text"]
            
            # ä¸ºæ ‡é¢˜ç”Ÿæˆé”šç‚¹
            anchor = self._create_anchor(text)
            
            # æ ¹æ®å±‚çº§æ·»åŠ ç¼©è¿›
            indent = "  " * (level - 1)
            
            # åˆ›å»ºç›®å½•é¡¹
            if level == 1:
                toc_lines.append(f"{indent}- [{text}](#{anchor})")
            else:
                bullet = "â€¢" if level <= 3 else "â—¦"
                toc_lines.append(f"{indent}  {bullet} [{text}](#{anchor})")
        
        toc_lines.append("")
        toc_lines.append("---")
        toc_lines.append("")
        
        return '\n'.join(toc_lines)
    
    def _update_existing_toc(self, existing_toc: str, new_headings: List[Dict]) -> str:
        """æ›´æ–°ç°æœ‰ç›®å½•"""
        # è§£æç°æœ‰ç›®å½•
        toc_lines = existing_toc.split('\n')
        
        # æå–ç°æœ‰æ¡ç›®
        existing_items = []
        for line in toc_lines:
            match = re.search(r'\[([^\]]+)\]\(#([^)]+)\)', line)
            if match:
                existing_items.append({
                    "text": match.group(1),
                    "anchor": match.group(2)
                })
        
        # åˆå¹¶æ–°æ—§æ¡ç›®
        merged_items = []
        
        # é¦–å…ˆæ·»åŠ æ–°æ ‡é¢˜
        for heading in new_headings:
            anchor = self._create_anchor(heading["text"])
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            exists = any(item["text"] == heading["text"] for item in existing_items)
            
            if not exists:
                indent = "  " * (heading["level"] - 1)
                bullet = "â€¢" if heading["level"] <= 3 else "â—¦"
                merged_items.append({
                    "level": heading["level"],
                    "text": heading["text"],
                    "anchor": anchor,
                    "line": f"{indent}  {bullet} [{heading['text']}](#{anchor})",
                    "is_new": True
                })
                self.stats["sections_merged"] += 1
        
        # æ·»åŠ ç°æœ‰æ¡ç›®ï¼ˆä¿ç•™é¡ºåºï¼‰
        for item in existing_items:
            # æ‰¾åˆ°å¯¹åº”çš„æ ‡é¢˜å±‚çº§
            heading_level = 2  # é»˜è®¤
            for heading in new_headings:
                if self._create_anchor(heading["text"]) == item["anchor"]:
                    heading_level = heading["level"]
                    break
            
            indent = "  " * (heading_level - 1)
            bullet = "â€¢" if heading_level <= 3 else "â—¦"
            merged_items.append({
                "level": heading_level,
                "text": item["text"],
                "anchor": item["anchor"],
                "line": f"{indent}  {bullet} [{item['text']}](#{item['anchor']})",
                "is_new": False
            })
        
        # æŒ‰å±‚çº§å’Œæ˜¯å¦ä¸ºæ–°çš„æ’åº
        merged_items.sort(key=lambda x: (x["level"], x["is_new"]))
        
        # é‡æ–°æ„å»ºç›®å½•
        updated_toc_lines = ["## ğŸ“‘ ç›®å½•", ""]
        
        for item in merged_items:
            if item["is_new"]:
                updated_toc_lines.append(f"{item['line']} *(æ–°)*")
            else:
                updated_toc_lines.append(item["line"])
        
        updated_toc_lines.append("")
        updated_toc_lines.append("---")
        updated_toc_lines.append("")
        
        return '\n'.join(updated_toc_lines)
    
    def _create_anchor(self, text: str) -> str:
        """ä¸ºæ ‡é¢˜åˆ›å»ºé”šç‚¹ID"""
        anchor = re.sub(r'[^\w\s-]', '', text)
        anchor = re.sub(r'[-\s]+', '-', anchor)
        anchor = anchor.lower().strip('-')
        
        if not anchor:
            anchor_hash = hashlib.md5(text.encode()).hexdigest()[:8]
            anchor = f"section-{anchor_hash}"
        
        return anchor
    
    def get_main_title(self, existing_title: str = "") -> str:
        """è·å–ä¸»æ ‡é¢˜"""
        if existing_title and self.config["add_main_title"]:
            # å¦‚æœå·²æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨å®ƒ
            return existing_title
        
        # ç”Ÿæˆæ–°æ ‡é¢˜
        if self.config["add_main_title"]:
            filename = self.input_path.stem
            return f"# ğŸ“š {filename} - å¯¹è¯å†å²æ¡£æ¡ˆé¦†"
        
        return ""
    
    def reorganize_content(self, structure: Dict[str, Any]) -> str:
        """
        é‡æ–°ç»„ç»‡å†…å®¹ï¼Œåˆ›å»ºæ¸…æ™°çš„æ–‡æ¡£
        
        Args:
            structure: å†…å®¹ç»“æ„ä¿¡æ¯
            
        Returns:
            é‡æ–°ç»„ç»‡åçš„å†…å®¹
        """
        output_lines = []
        all_headings = []
        
        # æ·»åŠ ä¸»æ ‡é¢˜
        main_title = self.get_main_title(structure.get("main_title", ""))
        if main_title:
            output_lines.append(main_title)
            output_lines.append("")
            
            # è®°å½•ä¸»æ ‡é¢˜
            all_headings.append({
                "level": 1,
                "text": main_title.replace('#', '').strip(),
                "original_level": 1,
                "line_num": 0
            })
        
        # å¤„ç†æ¯ä¸ªå¯¹è¯
        for dialog in structure["dialogs"]:
            dialog_id = dialog["id"]
            dialog_title = dialog["title"]
            
            # å¯¹è¯æ ‡é¢˜
            dialog_heading = f'## {dialog_id} - {dialog_title}'
            output_lines.append(dialog_heading)
            output_lines.append('')
            
            # è®°å½•å¯¹è¯æ ‡é¢˜
            all_headings.append({
                "level": 2,
                "text": f"{dialog_id} - {dialog_title}",
                "original_level": 2,
                "line_num": len(output_lines) - 2
            })
            
            # å¯¹è¯å…ƒæ•°æ®
            output_lines.append('**å¯¹è¯ä¿¡æ¯**')
            output_lines.append(f'- **å¯¹è¯ID**: `{dialog_id}`')
            output_lines.append(f'- **å¯¹è¯æ ‡é¢˜**: {dialog_title}')
            output_lines.append(f'- **å¯¹è¯è½®æ¬¡**: {len(dialog["turns"])}')
            output_lines.append('')
            
            # å¤„ç†æ¯ä¸ªå›åˆ
            for turn in dialog["turns"]:
                turn_id = turn["turn_id"]
                instruction_type = turn["instruction_type"]
                
                # å›åˆæ ‡é¢˜
                turn_heading = f'### å›åˆ {turn_id}: {instruction_type}'
                output_lines.append(turn_heading)
                output_lines.append('')
                
                # è®°å½•å›åˆæ ‡é¢˜
                all_headings.append({
                    "level": 3,
                    "text": f"å›åˆ {turn_id}: {instruction_type}",
                    "original_level": 3,
                    "line_num": len(output_lines) - 2
                })
                
                # æŒ‡ä»¤å†…å®¹
                output_lines.append('#### ğŸ“‹ æŒ‡ä»¤')
                if turn["instruction"]:
                    output_lines.append('```')
                    output_lines.append(turn["instruction"])
                    output_lines.append('```')
                else:
                    output_lines.append('*(æ— æŒ‡ä»¤æ–‡æœ¬)*')
                output_lines.append('')
                
                # å“åº”å†…å®¹ï¼ˆä¿®å¤åµŒå¥—ï¼‰
                output_lines.append('#### ğŸ¤– å“åº”')
                fixed_response, response_headings = self.fix_all_headings(
                    turn["response"], 
                    base_level=4  # å“åº”ä»4çº§å¼€å§‹
                )
                output_lines.append(fixed_response)
                
                # è®°å½•å“åº”ä¸­çš„æ ‡é¢˜
                for heading in response_headings:
                    heading["line_num"] += len(output_lines) - fixed_response.count('\n') - 2
                    all_headings.append(heading)
                
                # å›åˆå…ƒæ•°æ®
                if self.config["extract_key_points"]:
                    has_elements = False
                    elements_lines = []
                    
                    if turn["code_blocks"]:
                        has_elements = True
                        elements_lines.append('##### ğŸ’» æœ¬å›åˆä»£ç å—')
                        for cb in turn["code_blocks"]:
                            elements_lines.append(f'- `{cb["language"]}`: {cb["lines"]}è¡Œï¼Œ{cb["length"]}å­—ç¬¦')
                    
                    if turn["tables"]:
                        has_elements = True
                        elements_lines.append('##### ğŸ“Š æœ¬å›åˆè¡¨æ ¼')
                        for table in turn["tables"]:
                            elements_lines.append(f'- {table["row_count"]}è¡Œ Ã— {table["col_count"]}åˆ—è¡¨æ ¼')
                    
                    if turn["action_items"]:
                        has_elements = True
                        elements_lines.append('##### âœ… æœ¬å›åˆè¡ŒåŠ¨é¡¹')
                        for action in turn["action_items"][:5]:
                            elements_lines.append(f'- {action["text"]}')
                        if len(turn["action_items"]) > 5:
                            elements_lines.append(f'- ... è¿˜æœ‰ {len(turn["action_items"]) - 5} ä¸ªè¡ŒåŠ¨é¡¹')
                    
                    if has_elements:
                        output_lines.extend(elements_lines)
                        output_lines.append('')
                
                output_lines.append('---')
                output_lines.append('')
        
        # ç”Ÿæˆç›®å½•
        if self.config["generate_toc"] and all_headings:
            existing_toc = None
            if structure["has_existing_toc"]:
                # æå–ç°æœ‰ç›®å½•å†…å®¹
                lines = structure.get("full_content", "").split('\n')
                toc_start = structure["toc_start"]
                toc_end = structure["toc_end"] if structure["toc_end"] > 0 else len(lines)
                
                if 0 <= toc_start < toc_end <= len(lines):
                    existing_toc = '\n'.join(lines[toc_start:toc_end])
            
            toc_content = self.generate_table_of_contents(all_headings, existing_toc)
            
            if toc_content:
                # å°†ç›®å½•æ’å…¥åˆ°ä¸»æ ‡é¢˜ä¹‹å
                header_end = 0
                for i, line in enumerate(output_lines):
                    if line.startswith('# ') and i < len(output_lines) - 1:
                        if output_lines[i+1] == '':
                            header_end = i + 2
                            break
                
                # æ’å…¥ç›®å½•
                if header_end > 0:
                    toc_lines = toc_content.split('\n')
                    output_lines = output_lines[:header_end] + toc_lines + output_lines[header_end:]
                    self.stats["toc_updated"] = True
        
        return '\n'.join(output_lines)
    
    def generate_summary_report(self, structure: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        summary_lines = []
        
        summary_lines.append(f'# ğŸ“Š å¯¹è¯åˆ†ææŠ¥å‘Š - {self.input_path.name}')
        summary_lines.append('')
        summary_lines.append(f'**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        summary_lines.append(f'**åˆ†æå·¥å…·**: ConversationArchitect CLI v1.0')
        summary_lines.append('')
        
        # æ€»ä½“ç»Ÿè®¡
        summary_lines.append('## ğŸ“ˆ æ€»ä½“ç»Ÿè®¡')
        summary_lines.append('')
        summary_lines.append(f'- **è¾“å…¥æ–‡ä»¶**: {self.input_path.name}')
        summary_lines.append(f'- **æ–‡ä»¶å¤§å°**: {self.stats["file_size"]["input"]:,} å­—ç¬¦')
        summary_lines.append(f'- **å¯¹è¯æ€»æ•°**: {self.stats["dialogs_count"]}')
        summary_lines.append(f'- **å¯¹è¯è½®æ¬¡æ€»æ•°**: {self.stats["turns_count"]}')
        summary_lines.append(f'- **ä¿®å¤æ ‡é¢˜æ•°**: {self.stats["headings_fixed"]}')
        summary_lines.append(f'- **åˆå¹¶ç« èŠ‚æ•°**: {self.stats["sections_merged"]}')
        summary_lines.append(f'- **ç›®å½•æ›´æ–°**: {"æ˜¯" if self.stats["toc_updated"] else "å¦"}')
        summary_lines.append('')
        
        # å¯¹è¯è¯¦æƒ…
        summary_lines.append('## ğŸ“… å¯¹è¯è¯¦æƒ…')
        summary_lines.append('')
        
        for dialog in structure["dialogs"]:
            summary_lines.append(f'### {dialog["id"]}: {dialog["title"]}')
            summary_lines.append(f'  - **è½®æ¬¡**: {len(dialog["turns"])}')
            
            # ç»Ÿè®¡æŒ‡ä»¤ç±»å‹
            instruction_types = {}
            for turn in dialog["turns"]:
                itype = turn["instruction_type"]
                instruction_types[itype] = instruction_types.get(itype, 0) + 1
            
            if instruction_types:
                type_str = ', '.join([f'{k}({v})' for k, v in instruction_types.items()])
                summary_lines.append(f'  - **æŒ‡ä»¤ç±»å‹**: {type_str}')
            
            summary_lines.append('')
        
        # å¤„ç†å»ºè®®
        summary_lines.append('## ğŸ’¡ å¤„ç†å»ºè®®')
        summary_lines.append('')
        
        if self.stats["headings_fixed"] > 0:
            summary_lines.append(f'1. **æ ‡é¢˜å±‚çº§å·²ä¿®å¤**: {self.stats["headings_fixed"]}ä¸ªæ ‡é¢˜å±‚çº§å·²è°ƒæ•´')
        
        if self.stats["sections_merged"] > 0:
            summary_lines.append(f'2. **å†…å®¹å·²åˆå¹¶**: {self.stats["sections_merged"]}ä¸ªæ–°ç« èŠ‚å·²æ·»åŠ åˆ°ç›®å½•')
        
        if self.stats["toc_updated"]:
            summary_lines.append('3. **ç›®å½•å·²æ›´æ–°**: æ–‡æ¡£ç›®å½•å·²æ›´æ–°ä»¥åæ˜ æœ€æ–°å†…å®¹')
        
        if len(structure["dialogs"]) > 5:
            summary_lines.append('4. **å¯¹è¯è¾ƒå¤š**: å»ºè®®è€ƒè™‘å°†é•¿å¯¹è¯æ‹†åˆ†ä¸ºå¤šä¸ªæ–‡ä»¶')
        
        summary_lines.append('')
        summary_lines.append('---')
        summary_lines.append('*æŠ¥å‘Šç»“æŸ*')
        
        return '\n'.join(summary_lines)
    
    def save_output_file(self, content: str) -> Path:
        """ä¿å­˜è¾“å‡ºæ–‡ä»¶"""
        try:
            with open(self.output_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # æ›´æ–°ç»Ÿè®¡
            file_size = len(content.encode('utf-8'))
            self.stats["file_size"]["output"] = file_size
            
            print(f"[âˆš] å·²ä¿å­˜: {self.output_path} ({file_size:,} å­—èŠ‚)")
            return self.output_path
        except Exception as e:
            print(f"[Ã—] ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def export_statistics_json(self) -> Path:
        """å¯¼å‡ºå¤„ç†ç»Ÿè®¡ä¸ºJSON"""
        if self.stats["processing_time"] is None:
            self.stats["processing_time"] = datetime.now().isoformat()
        
        # è®¡ç®—å¤„ç†æ‘˜è¦
        self.stats["summary"] = {
            "status": "success",
            "dialogs_processed": self.stats["dialogs_count"],
            "turns_processed": self.stats["turns_count"],
            "file_saved": str(self.output_path)
        }
        
        output_path = self.output_path.parent / f"{self.output_path.stem}_statistics.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, ensure_ascii=False, indent=2)
        
        print(f"[âˆš] ç»Ÿè®¡ä¿¡æ¯å·²å¯¼å‡º: {output_path}")
        return output_path
    
    def process(self) -> Dict[str, Any]:
        """
        ä¸»å¤„ç†æµç¨‹
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        print("\n" + "="*60)
        print("ğŸ¤– ConversationArchitect CLI - å¼€å§‹å¤„ç†å¯¹è¯è®°å½•")
        print("="*60)
        
        start_time = datetime.now()
        
        try:
            # 1. è¯»å–æ–‡ä»¶
            print("\n[1/5] ğŸ“– è¯»å–å¯¹è¯æ–‡ä»¶...")
            content = self.read_conversation_file()
            if not content:
                return {"success": False, "error": "æ— æ³•è¯»å–æ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©º"}
            
            # 2. åˆ†æå†…å®¹ç»“æ„
            print("[2/5] ğŸ” åˆ†æå†…å®¹ç»“æ„...")
            structure = self.detect_content_structure(content)
            structure["full_content"] = content
            
            if not structure["dialogs"]:
                return {"success": False, "error": "æœªæ£€æµ‹åˆ°å¯¹è¯å†…å®¹"}
            
            # 3. é‡æ–°ç»„ç»‡å†…å®¹
            print("[3/5] ğŸ—ï¸ é‡æ–°ç»„ç»‡å†…å®¹...")
            organized_content = self.reorganize_content(structure)
            
            # 4. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            print("[4/5] ğŸ“Š ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
            summary_content = self.generate_summary_report(structure)
            
            # 5. ä¿å­˜è¾“å‡ºæ–‡ä»¶
            print("[5/5] ğŸ’¾ ä¿å­˜è¾“å‡ºæ–‡ä»¶...")
            
            # ä¿å­˜ä¸»è¦æ–‡æ¡£
            main_doc_path = self.save_output_file(organized_content)
            
            # ä¿å­˜æ€»ç»“æŠ¥å‘Š
            summary_path = self.output_path.parent / f"{self.output_path.stem}_summary.md"
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(summary_content)
            print(f"[âˆš] æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")
            
            # å¯¼å‡ºç»Ÿè®¡
            stats_path = self.export_statistics_json()
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            end_time = datetime.now()
            processing_duration = end_time - start_time
            self.stats["processing_duration_seconds"] = processing_duration.total_seconds()
            
            print("\n" + "="*60)
            print("ğŸ‰ å¤„ç†å®Œæˆï¼")
            print("="*60)
            print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"  - å¯¹è¯æ•°é‡: {self.stats['dialogs_count']}")
            print(f"  - å›åˆæ•°é‡: {self.stats['turns_count']}")
            print(f"  - ä¿®å¤æ ‡é¢˜: {self.stats['headings_fixed']}")
            print(f"  - åˆå¹¶ç« èŠ‚: {self.stats['sections_merged']}")
            print(f"  - å¤„ç†æ—¶é—´: {processing_duration.total_seconds():.2f}ç§’")
            print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
            print(f"  ğŸ“„ {main_doc_path.name}")
            print(f"  ğŸ“Š {summary_path.name}")
            print(f"  ğŸ“‹ {stats_path.name}")
            print(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {self.output_path.parent}")
            print("="*60)
            
            return {
                "success": True,
                "dialogs_count": self.stats["dialogs_count"],
                "turns_count": self.stats["turns_count"],
                "headings_fixed": self.stats["headings_fixed"],
                "sections_merged": self.stats["sections_merged"],
                "processing_time": processing_duration.total_seconds(),
                "output_files": {
                    "main": str(main_doc_path),
                    "summary": str(summary_path),
                    "statistics": str(stats_path)
                }
            }
            
        except Exception as e:
            print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='å¯¹è¯è®°å½•ç»“æ„åŒ–å¤„ç†å·¥å…· CLI ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s "å¯¹è¯è®°å½•.md"                    # åŸºæœ¬ä½¿ç”¨ï¼ˆè¾“å‡ºåˆ°åŒç›®å½•ï¼‰
  %(prog)s "å¯¹è¯è®°å½•.md" -o "è¾“å‡ºæ–‡ä»¶.md"    # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  %(prog)s "å¯¹è¯è®°å½•.md" -s "_clean"        # æŒ‡å®šè¾“å‡ºæ–‡ä»¶åç¼€
  %(prog)s "å¯¹è¯è®°å½•.md" --no-toc           # ä¸ç”Ÿæˆç›®å½•
  %(prog)s "å¯¹è¯è®°å½•.md" --no-title         # ä¸æ·»åŠ æ€»æ ‡é¢˜
        """
    )
    
    parser.add_argument(
        'input',
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»ï¼‰'
    )
    
    parser.add_argument(
        '-o', '--output',
        dest='output_file',
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼šè¾“å…¥æ–‡ä»¶_organized.mdï¼‰'
    )
    
    parser.add_argument(
        '-s', '--suffix',
        dest='suffix',
        default='_organized',
        help='è¾“å‡ºæ–‡ä»¶åç¼€ï¼ˆå½“ä¸æŒ‡å®š-oæ—¶ä½¿ç”¨ï¼Œé»˜è®¤ï¼š_organizedï¼‰'
    )
    
    parser.add_argument(
        '--no-toc',
        action='store_true',
        help='ä¸ç”Ÿæˆç›®å½•'
    )
    
    parser.add_argument(
        '--no-title',
        action='store_true',
        help='ä¸æ·»åŠ æ€»æ ‡é¢˜'
    )
    
    parser.add_argument(
        '--no-summary',
        action='store_true',
        help='ä¸ç”Ÿæˆæ€»ç»“æŠ¥å‘Š'
    )
    
    parser.add_argument(
        '--no-merge',
        action='store_true',
        help='ä¸åˆå¹¶å·²ä¼˜åŒ–å†…å®¹'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯'
    )
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("="*60)
    print("ğŸ¤– ConversationArchitect CLI v1.0")
    print("çº¯å‘½ä»¤è¡Œå¯¹è¯è®°å½•å¤„ç†å·¥å…·")
    print("="*60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ - {args.input}")
        sys.exit(1)
    
    if not input_path.is_file():
        print(f"âŒ é”™è¯¯ï¼šè¾“å…¥è·¯å¾„ä¸æ˜¯æ–‡ä»¶ - {args.input}")
        sys.exit(1)
    
    # åˆ›å»ºå¤„ç†å™¨
    try:
        architect = ConversationArchitectCLI(
            input_path=str(input_path),
            output_path=args.output_file,
            suffix=args.suffix
        )
        
        # æ ¹æ®å‚æ•°è°ƒæ•´é…ç½®
        if args.no_toc:
            architect.config["generate_toc"] = False
        
        if args.no_title:
            architect.config["add_main_title"] = False
        
        if args.no_summary:
            architect.config["generate_summary"] = False
        
        if args.no_merge:
            architect.config["smart_merge"] = False
        
        # å¤„ç†å¯¹è¯
        result = architect.process()
        
        if result["success"]:
            print("\nâœ… å¤„ç†æˆåŠŸå®Œæˆï¼")
            print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
            print(f"1. æ‰“å¼€ '{Path(result['output_files']['main']).name}' æŸ¥çœ‹ç»“æ„åŒ–å¯¹è¯")
            print(f"2. æŸ¥çœ‹ '{Path(result['output_files']['summary']).name}' è·å–åˆ†ææŠ¥å‘Š")
            print(f"3. ä½¿ç”¨ '{Path(result['output_files']['statistics']).name}' è¿›è¡Œæ•°æ®åˆ†æ")
            print(f"4. å¦‚éœ€é‡æ–°å¤„ç†ï¼Œåˆ é™¤è¾“å‡ºæ–‡ä»¶å¹¶é‡æ–°è¿è¡Œæœ¬ç¨‹åº")
        else:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()